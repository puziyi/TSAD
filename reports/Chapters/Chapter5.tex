% Chapter 5

\chapter{Conclusion and Future Work} % Main chapter title

\label{Chapter5} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------

\section{Conclusion}
In our project, we first reviewed different existing research on sequence modeling methods, and find the characteristics inside them. Then we used common machine learning training datasets to check avaliability of TCN and accertain its power over other sequential models. Next, we checked predict ability of TCN over other relatively traditional sequential models, such as Gated recurrent units (GRUs), long short-term memory (LSTM), vanilla RNN and False nearest neighbor (FNN),  by using some specific sequence datas. And in order to have a better result, we tune the hyper parameters in TCN model. After comparison, TCN showed itself as both robust and accuracy even amongst deep learning models. 

However, it can not demonstrated convincing performance. Next we try to discover the data sensitivity of TCN model and add LSTM model as comparison. We find that TCN performs better than LSTM in fluctuated data. And for short data size, TCN need more time to attain a good result, while for long and huge data, TCN have ability to perform better. As TCN is sensitive to the size of dataset, we adjust the TCN's convolutional kernel to increase the receptive field size, which improves the final performance significantly and also increases the training efficiency. Besides, we try to upgrade our TCN model by importing attention mechanism to decrease the computational cost.

\section{Further Work}
However, our group still found some limitations and hope to do more improvements on following aspects:
\begin{itemize}
    \item Limited dataset. In project we tried several different datasets and choose Gefcom2014 electronic data as object dataset. The Gefcom2014 data have some good features such as regular and smooth. However, it also bring limitation to model fitting and make the experiment not that convincing. And we also need more type of data to verify the characteristics we found in TCN. So it's better for us to try to do more test the finding of our project with more grid load datasets for example, from different countries or states.
    \item Higher predict accuracy with lower computational cost. During this project, we mainly focus on the predict accuracy in anomaly period, one significant drawback is that much computational resources, not only time consuming but also high memory and CPU occupation. Although we have modified convolution kernals and network structures and indeed imporve a lot, we plan to go further on chasing higher and more stable predict accuracy in a cost-saving manner. 
    \item Integrete into reality application situations. As we mentioned before, grid load prediction and anomaly detection could be used into various situations, hence, if possible, we want to integrete our model into certain situations, and make real-time predictions for this electronic soecity.
\end{itemize}